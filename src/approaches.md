# Подходы

Ниже предоставлен вольный пересказ основных подходов и трюков, используемых при реализации памяти для агентов.

- структура данных: текстовая бд, графовая бд, скользящий контекст
- единицы памяти
- суммаризация как необходимое условие понимания текста
- дедупликация знаний
- подбор кандидатов: text retrieval, node/edge retrieval, BFS
- организация промтов
- temporal awareness

## Структура данных

Память для агентов хранится как текстовая информация, организованная как некоторая структура данных, позволяющая эффективный поиск и добавление данных. В результате анализа популярных статей, я встретил следующие варианты:
- скользящая суммаризация
- векторный индекс на сырых данных
- иерархическая кластеризация
- граф знаний


Исторически векторный индекс, вдохновленный RAG, появился одним из первых. Все остальные подходы можно рассматривать как способы преодолеть его недостатки.

### Скользящая суммаризация

Идея скользящей суммаризации как механизма памяти проста: LLM-приложение поддерживает текстовое описание всех имеющихся данных и обновляет его с приходом новой информации. Например, скользящая суммаризация используется в [MemoryBank, 2023]() и [LD-Agent, 2024]() для поддержания портрета пользователя. В [MemGPT, 2024]() скользящее саммари служит рабочим контекстом для решения всех задач подобному тому, как  ОЗУ хранит всю информацию, необходимую для работы процессов. В [Mem0, 2025]() скользящее саммари текущего диалога вместе с $m$ последними сообщениями используется, чтобы не подавать весь диалог на вход LLM.

Можно сказать, что такой подход полезен для отражения изменяющегося состояния отдельных объектов, но не применим для случаев, когда нужно анализировать сложные взаимосвязи между фактами, которые были актуальны в прошлом.

### Векторный индекс на сырых данных

Векторный индекс на сырых данных прост с точки зрения реализации. По сути это non-lossy хранилище данных, которое дает возможность отследить источник мыслей агента и опирается на эффективные алгоритмы векторного поиска. Например, [MemoryBank, 2023]() хранит сообщения пользователя, а не поддерживает скользящий индекс. Однако сегодня авторы отмечают ряд недостатков RAG в приложении к агентской памяти.

Главным образом, использование сырых данных в качестве контекста для LLM не дает LLM глобального представления о всей имеющейся информации. Фрагменты документов или предыдущих диалогов --- это не то, что нужно для полноценного понимания текущего состояния среды.

Последние работы на тему агентской памяти не используют RAG в чистом виде, однако для реальных приложений такое решение может стать неплохой стартовой точкой, а для исследований --- разумным бейзлайном.

### Иерархическая кластеризация

Иерархическая кластеризация имеет прямой целью обобщить сырые данные, чтобы получить глобальное представление о состоянии среды. Например, в [RAPTOR, 2024]() эмбединги сырых данных кластеризуются рекурсивно, до получения древовидной структуры. Причем, каждый каждый кластер презентуется не центроидом, а LLM-generated суммаризацией. Чем ближе суммаризация к корню дерева, тем более глобальное представление оно дает о состоянии среды.

### Граф знаний

## Единицы памяти