# Введение в проблему

LLM-агент — это подход к разработке LLM-приложений, при котором на плечи LLM кладутся интеллектуальные задачи, связанные с анализом текстов, взаимодействием с пользователем, генерацией и поиском контента. Такие задачи характеризуются наличием внешних данных, необходимостью автономного принятия решений и использованием инструментов. Чаще всего действие агента происходит в некоторой среде, будь то чат с пользователем, редактор документов или абстрактный пользовательский интерфейс или поток данных.

При разработке LLM-приложений удобно представлять, что LLM — это человек, воспринимающий текстовые инструкции. Важное отличие в том, что настоящему человеку достаточно единожды пройти профподготовку, чтобы решать все рабочие задачи, тогда как LLM "сбрасывается до заводских" после каждого обращения. Необходимы дополнительные средства для поддержания правильного текстового контекста для LLM. Он может состоять из: 1) инструкций по выполнению задачи; 2) данных, которые нужно обработать; 3) внешних знаний, которых нет в весах LLM; 4) информации о пользователе. От корректности поддерживаемого контекста зависит согласованность результатов последовательных вызовов LLM в рамках одной или нескольких сессий работы приложения.

Простейший способ поддержания контекста — подавать на вход LLM абсолютно всю информацию, относящуюся к решению данной задачи. Такой подход опирается на способность LLM мыслить в рамках предоставленного контекста. Это разумно, поскольку максимальный размер входа современных LLM уже позволяет работать даже с "Войной и миром" (~580k токенов). Однако для агентских приложений такой подход нежелателен, так как требует больше денег и времени выполнения, что критично для высоконагруженных приложений со сложной логикой последовательных LLM-вызовов. Более того, чем сложнее задача, лежащая на плечах LLM, тем: 1) чаще LLM галлюцинирует, 2) сложнее оценить работу LLM, 3) сложнее отладить ошибки в рассуждениях LLM. Поэтому контекст должен быть полным, но лаконичным.

Решением задачи предоставления правильного контекста может стать использование внешнего по отношению к LLM механизма памяти. Он должен поддерживать простейшие операции добавления и поиска данных, составляющих корректный контекст, полный и лаконичный.
