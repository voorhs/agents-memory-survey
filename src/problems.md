# Проблемы реализации памяти

## Проблема гранулярности

Одна из важных проблем, которую нужно решить при реализации памяти для агента, — насколько большой или маленькой должна быть единица памяти. Есть две крайности: 1) хранить каждое сообщение или каждый turn или их суммаризацию, 2) хранить целиком диалог или его суммаризацию. Промежуточный вариант — научиться сегментировать диалог. Именно в таком разрезе эту проблему исследовали в статьях [SeCom, 2025]() и [Nemori, 2025](). Их решением был третий вариант, т.е. научиться сегментировать.

На мой взгляд другие работы тоже обращаются к этой проблеме, но предлагают искать решение в других разрезах:
- [RAPTOR, 2024](), [GraphRAG, 2024]() и [Zep, 2025]() используют иерархическую структуру данных, чтобы искать сразу на всех уровнях гранулярности
- [LD-Agent, 2025](), [A-Mem, 2025](), [Theanine, 2025](), [RMM, 2025]() суммаризируют сессии в виде набора "воспоминаний"/"событий"/"эпизодов", сразу производя фильтрацию и отбирая нужную гранулярность на этапе формирования воспоминаний
- [Mem0, 2025]() пытается выделять "воспоминания"/"темы" с учетом контекста из последних сообщений в диалоге

## Дедупликация данных

Одной из ключевых проблем поддержания лаконичного хранилища данных является обработка дупликатов. Дело в том, что одна и та же информация может появляться много раз: в разных документах, в разных сообщениях, в разных пользовательских сессиях. Если используемая нами структура данных не умеет обрабатывать добавление уже имеющейся информации, то извлекаемые воспоминания будут избыточными. Поэтому почти по всех увиденных мною работах встречается механизм дедупликации в том или ином виде.

В [GraphRAG, 2024]() каждая новая сущность сначала ищется среди имеющихся — и если такая уже есть, то она просто обновляется с учетом нового контента. Примерно так же происходит в [Zep, 2025](), [Mem0, 2025](), [RMM, 2025]().

## Инвалидация данных

Память может быть противоречивой, если в ней нет механизма инвалидации старых фактов взамен новых. В [Zep, 2025]() для этой цели хранятся таймстемпы, причем сразу для двух таймлайнов (абсолютного и относительного). В [GraphRAG, 2024](), [RAPTOR, 2024](), [RMM, 2025]() эта проблема решается вместе с проблемой дедупликации. В [MemoryBank, 2023]() и [LD-Agent, 2025]() используется экспоненциальный закон забывания, так что инвалидируются не те факты, которые противоречат новой пришедшей информации, а просто все факты которые живут достаточно долго. В случае [Theanine, 2025]() противоречащие факты разрешаются за счет того, что они выстроены в таймлайн, что позволяет LLM понять какой факт верен уже во время генерации ответа (что очень похоже на [Zep, 2025]). [A-Mem, 2025]() инвалидирует старые факты за счет того, что просто обновляет контент вершин.
