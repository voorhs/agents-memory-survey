# Проблемы реализации памяти

## Проблема гранулярности

Одна из важных проблем, которую нужно решить при реализации памяти для агента, — насколько большой или маленькой должна быть единица памяти. Есть две крайности: 1) хранить каждое сообщение или каждый turn или их суммаризацию, 2) хранить целиком диалог или его суммаризацию. Промежуточный вариант — научиться сегментировать диалог. Именно в таком разрезе эту проблему исследовали в статьях [SeCom] и [Nemori]. Их решением был третий вариант, т.е. научиться сегментировать.

На мой взгляд другие работы тоже обращаются к этой проблеме, но предлагают искать решение в других разрезах:
- [RAPTOR], [GraphRAG] и [Zep] используют иерархическую структуру данных, чтобы искать сразу на всех уровнях гранулярности
- [LD-Agent], [A-Mem], [Theanine], [RMM] суммаризируют сессии в виде набора "воспоминаний"/"событий"/"эпизодов", сразу производя фильтрацию и отбирая нужную гранулярность на этапе формирования воспоминаний
- [Mem0] пытается выделять "воспоминания"/"темы" с учетом контекста из последних сообщений в диалоге

## Дедупликация данных

Одной из ключевых проблем поддержания лаконичного хранилища данных является обработка дупликатов. Дело в том, что одна и та же информация может появляться много раз: в разных документах, в разных сообщениях, в разных пользовательских сессиях. Если используемая нами структура данных не умеет обрабатывать добавление уже имеющейся информации, то извлекаемые воспоминания будут избыточными. Поэтому почти по всех увиденных мною работах встречается механизм дедупликации в том или ином виде.

В [GraphRAG] каждая новая сущность сначала ищется среди имеющихся — и если такая уже есть, то она просто обновляется с учетом нового контента. Примерно так же происходит в [Zep], [Mem0], [RMM].

## Инвалидация данных

Память может быть противоречивой, если в ней нет механизма инвалидации старых фактов взамен новых. В [Zep] для этой цели хранятся таймстемпы, причем сразу для двух таймлайнов (абсолютного и относительного). В [GraphRAG], [RAPTOR], [RMM] эта проблема решается вместе с проблемой дедупликации. В [MemoryBank] и [LD-Agent] используется экспоненциальный закон забывания, так что инвалидируются не те факты, которые противоречат новой пришедшей информации, а просто все факты которые живут достаточно долго. В случае [Theanine] противоречащие факты разрешаются за счет того, что они выстроены в таймлайн, что позволяет LLM понять какой факт верен уже во время генерации ответа (что очень похоже на [Zep, 2025]). [A-Mem] инвалидирует старые факты за счет того, что просто обновляет контент вершин.
